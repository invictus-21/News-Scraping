{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> USER AGENTS </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> <center> COLLECT URLS </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1600 urls were collected in 399.9496066570282 second.\n",
      "4.0 urls were collected per second on average.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "keyword = \"cinayet\"\n",
    "start_date = \"01/01/2022\"\n",
    "finish_date = \"01/01/2023\"\n",
    "main_category = \"gundem\"    \n",
    "\n",
    "urls = []\n",
    "titles = []\n",
    "abstracts = []\n",
    "dates = []\n",
    "\n",
    "url_count = 0\n",
    "service = Service('/chromedriver.exe')\n",
    "service.start()\n",
    "driver = webdriver.Remote(service.service_url)\n",
    "pages = list(range(1,161))\n",
    "\n",
    "for page in pages:\n",
    "    try:\n",
    "        search_url = f\"https://www.hurriyet.com.tr/arama/#/?page={page}&key={keyword}&order=Yeniden%20Eskiyewhere=hurriyet&how=Article&and={keyword}&startDate={start_date}&finishDate={finish_date}&platform=hurriyet&mainCategory=/{main_category}/&isDetail=true\"\n",
    "        driver.get(search_url)\n",
    "        time.sleep(1)\n",
    "        div_content_tags = driver.find_elements(By.XPATH,\"//div[@class='hs-cnn-content']\")\n",
    "        for div_content_tag in div_content_tags:\n",
    "            a_tag = div_content_tag.find_element(By.TAG_NAME,\"a\")\n",
    "            urls.append(a_tag.get_attribute(\"href\"))\n",
    "        p_title_tags = driver.find_elements(By.XPATH,\"//p[@class='hs-cnnc-title']\")\n",
    "        for p_title_tag in p_title_tags:\n",
    "            titles.append(p_title_tag.get_attribute(\"innerHTML\"))\n",
    "        p_text_tags = driver.find_elements(By.XPATH,\"//p[@class='hs-cnnc-text']\")\n",
    "        for p_text_tag in p_text_tags:\n",
    "            abstracts.append(p_text_tag.get_attribute(\"innerHTML\"))\n",
    "        p_date_tags = driver.find_elements(By.XPATH,\"//p[@class='hs-cnncc-date']\")\n",
    "        for p_date_tag in p_date_tags:\n",
    "            dates.append(p_date_tag.get_attribute(\"innerHTML\")) \n",
    "        url_count += 10\n",
    "        print(f\"{url_count} urls were fetched so far\", sep=' ', end='', flush=True)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(\"Last Page\")\n",
    "        break\n",
    "    \n",
    "driver.quit()  \n",
    "print(f\"\\n\\n{url_count} urls were collected in {time.time() - start} second.\")\n",
    "print(f\"{round(url_count / (time.time() - start), 2)} urls were collected per second on average.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.1.2023</th>\n",
       "      <td>http://www.hurriyet.com.tr/gundem/manisa-saruh...</td>\n",
       "      <td>Manisa Saruhanlı'da korkunç olay! Üç eşini de ...</td>\n",
       "      <td>Necati Akpınar (58), 1 ay önce dini nikahla bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1.2023</th>\n",
       "      <td>http://www.hurriyet.com.tr/gundem/o-cinayette-...</td>\n",
       "      <td>O cinayette 3 gözaltı</td>\n",
       "      <td>Ankara’da, eski Ülkü Ocakları Eğitim ve Kültür...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.12.2022</th>\n",
       "      <td>http://www.hurriyet.com.tr/gundem/ankarada-sil...</td>\n",
       "      <td>Ankara’da silahlı kavga: 3 ölü, 1 yaralı</td>\n",
       "      <td>Ankara’nın Mamak ilçesinde bir kafede çıkan si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.12.2022</th>\n",
       "      <td>http://www.hurriyet.com.tr/gundem/copu-dokmeye...</td>\n",
       "      <td>Çöpü dökmeyen kardeşini 38 yerinden bıçaklayar...</td>\n",
       "      <td>Ankara'da çöpü dökmesini isteyince kendisini t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.12.2022</th>\n",
       "      <td>http://www.hurriyet.com.tr/gundem/bayrampasada...</td>\n",
       "      <td>Bayrampaşa'da korkunç olay! Önce darbettiler s...</td>\n",
       "      <td>İstanbul Bayrampaşa'da bir eğlence mekanında M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1.2022</th>\n",
       "      <td>http://www.hurriyet.com.tr/gundem/kirsehirde-a...</td>\n",
       "      <td>Kırşehir'de ağabey-kardeş, 23 gün arayla öldür...</td>\n",
       "      <td>Kırşehir'in Kaman ilçesinde husumetlileri tara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1.2022</th>\n",
       "      <td>http://www.hurriyet.com.tr/gundem/eglence-cina...</td>\n",
       "      <td>Eğlence cinayetine ömür boyu hapis cezası</td>\n",
       "      <td>Bursa’da, arkadaşlarıyla eğlenmek için gittiği...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1.2022</th>\n",
       "      <td>http://www.hurriyet.com.tr/gundem/bagcilarda-y...</td>\n",
       "      <td>Bağcılar’daki cinayet, intihar çıktı: Hepinizi...</td>\n",
       "      <td>Bağcılar’da yılbaşı gecesi 14 yaşındaki Hüseyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1.2022</th>\n",
       "      <td>http://www.hurriyet.com.tr/gundem/arkadas-grub...</td>\n",
       "      <td>Arkadaş grubunun yılbaşı eğlencesinde bıçaklı ...</td>\n",
       "      <td>Tokat'ın Erbaa ilçesinde Nurettin Öztürk (56),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1.2022</th>\n",
       "      <td>http://www.hurriyet.com.tr/gundem/rahat-uyu-ce...</td>\n",
       "      <td>Rahat uyu Ceren</td>\n",
       "      <td>Akademisyen Ceren Damar Şenel’in vahşice öldür...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1595 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          url  \\\n",
       "date                                                            \n",
       "1.1.2023    http://www.hurriyet.com.tr/gundem/manisa-saruh...   \n",
       "1.1.2023    http://www.hurriyet.com.tr/gundem/o-cinayette-...   \n",
       "31.12.2022  http://www.hurriyet.com.tr/gundem/ankarada-sil...   \n",
       "30.12.2022  http://www.hurriyet.com.tr/gundem/copu-dokmeye...   \n",
       "30.12.2022  http://www.hurriyet.com.tr/gundem/bayrampasada...   \n",
       "...                                                       ...   \n",
       "2.1.2022    http://www.hurriyet.com.tr/gundem/kirsehirde-a...   \n",
       "1.1.2022    http://www.hurriyet.com.tr/gundem/eglence-cina...   \n",
       "1.1.2022    http://www.hurriyet.com.tr/gundem/bagcilarda-y...   \n",
       "1.1.2022    http://www.hurriyet.com.tr/gundem/arkadas-grub...   \n",
       "1.1.2022    http://www.hurriyet.com.tr/gundem/rahat-uyu-ce...   \n",
       "\n",
       "                                                        title  \\\n",
       "date                                                            \n",
       "1.1.2023    Manisa Saruhanlı'da korkunç olay! Üç eşini de ...   \n",
       "1.1.2023                                O cinayette 3 gözaltı   \n",
       "31.12.2022           Ankara’da silahlı kavga: 3 ölü, 1 yaralı   \n",
       "30.12.2022  Çöpü dökmeyen kardeşini 38 yerinden bıçaklayar...   \n",
       "30.12.2022  Bayrampaşa'da korkunç olay! Önce darbettiler s...   \n",
       "...                                                       ...   \n",
       "2.1.2022    Kırşehir'de ağabey-kardeş, 23 gün arayla öldür...   \n",
       "1.1.2022            Eğlence cinayetine ömür boyu hapis cezası   \n",
       "1.1.2022    Bağcılar’daki cinayet, intihar çıktı: Hepinizi...   \n",
       "1.1.2022    Arkadaş grubunun yılbaşı eğlencesinde bıçaklı ...   \n",
       "1.1.2022                                      Rahat uyu Ceren   \n",
       "\n",
       "                                                     abstract  \n",
       "date                                                           \n",
       "1.1.2023    Necati Akpınar (58), 1 ay önce dini nikahla bi...  \n",
       "1.1.2023    Ankara’da, eski Ülkü Ocakları Eğitim ve Kültür...  \n",
       "31.12.2022  Ankara’nın Mamak ilçesinde bir kafede çıkan si...  \n",
       "30.12.2022  Ankara'da çöpü dökmesini isteyince kendisini t...  \n",
       "30.12.2022  İstanbul Bayrampaşa'da bir eğlence mekanında M...  \n",
       "...                                                       ...  \n",
       "2.1.2022    Kırşehir'in Kaman ilçesinde husumetlileri tara...  \n",
       "1.1.2022    Bursa’da, arkadaşlarıyla eğlenmek için gittiği...  \n",
       "1.1.2022    Bağcılar’da yılbaşı gecesi 14 yaşındaki Hüseyi...  \n",
       "1.1.2022    Tokat'ın Erbaa ilçesinde Nurettin Öztürk (56),...  \n",
       "1.1.2022    Akademisyen Ceren Damar Şenel’in vahşice öldür...  \n",
       "\n",
       "[1595 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_urls = pd.DataFrame({\"url\":urls, \"title\":titles, \"abstract\":abstracts, \"date\":dates })\n",
    "scraped_urls.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_urls.to_excel(\"outputs/scraped_urls.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> COLLECT NEWS CONTENTS </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with open('news-urls.txt') as f:\n",
    "    news_urls = f.readlines()\n",
    "    \n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\"\n",
    "}\n",
    "    \n",
    "url_texts = [] \n",
    "f = open(\"scraped_news_contents.txt\", \"a\")\n",
    "\n",
    "for url in news_urls:\n",
    "    r = requests.get(url.strip(), headers=headers)\n",
    "    print(r)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> <center> TEXT ANALYZING </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt: str = \"I have no question\", creativity: float = 0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        prompt (str): user input prompt\n",
    "\n",
    "    Returns:\n",
    "        str: response of chatgpt\n",
    "    \"\"\"\n",
    "    completions = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=creativity / 10,\n",
    "    )\n",
    "    return completions.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('key.txt') as f:\n",
    "    openai.api_key = f.readlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with open('scraped_news_contents.txt') as f:\n",
    "    scraped_news_content = f.read()\n",
    "f = open(\"analyzed_news_details.txt\", \"a\")\n",
    "i=0\n",
    "for news_content in scraped_news_content.split(\"DELIMITER\"):\n",
    "    print(i)\n",
    "    i+=1\n",
    "    question = \"Please tell me the name and gender of the person who kills, \\\n",
    "    the name and the gender of the person who is killed, and date in a uniform format like this: name_of_killer, gender_of killer, name_of_killed, gender_of_killed, date   \\\n",
    "    according to this new: (Thank you) \"\n",
    "    question += news_content\n",
    "    answer = generate_response(question)\n",
    "    print(\"answer given\")\n",
    "    result = answer + \"\\nDELIMITER\\n\"\n",
    "    f.write(result)\n",
    "    print(answer)\n",
    "    \n",
    "f.close()\n",
    "print(f\"{len(urls)} urls were fetched in {time.time() - start} second.\")\n",
    "print(f\"{round(len(urls) / (time.time() - start), 2)} urls were fetched per second on average.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "scraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
